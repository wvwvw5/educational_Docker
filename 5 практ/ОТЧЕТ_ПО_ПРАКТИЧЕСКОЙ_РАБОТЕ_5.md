# ОТЧЕТ ПО ПРАКТИЧЕСКОЙ РАБОТЕ №5
## Система мониторинга с Prometheus и Grafana

---

## ОГЛАВЛЕНИЕ

1. [Цель работы](#цель-работы)
2. [Используемое окружение](#используемое-окружение)
3. [Архитектура системы мониторинга](#архитектура-системы-мониторинга)
4. [Развертывание приложения с метриками Prometheus](#развертывание-приложения-с-метриками-prometheus)
5. [Стандартные метрики производительности](#стандартные-метрики-производительности)
6. [Пользовательские метрики приложения](#пользовательские-метрики-приложения)
7. [Настройка визуализации в Grafana](#настройка-визуализации-в-grafana)
8. [Настройка алертинга](#настройка-алертинга)
9. [Интеграция с Telegram и Email](#интеграция-с-telegram-и-email)
10. [Демонстрация работы алертов](#демонстрация-работы-алертов)
11. [Дополнительные материалы и скриншоты](#дополнительные-материалы-и-скриншоты)
12. [Выводы](#выводы)

---

## ЦЕЛЬ РАБОТЫ

Создать систему мониторинга работы приложения с использованием формата Prometheus и инструмента визуализации Grafana. Реализовать сбор стандартных и пользовательских метрик, настроить визуализацию с легендами, а также организовать систему оповещений через Telegram-бот и Email с демонстрацией всех статусов алертов (Firing, Pending, Normal, Resolved).

---

## ИСПОЛЬЗУЕМОЕ ОКРУЖЕНИЕ

- **ОС**: MacOS (Darwin 25.0.0)
- **Docker Desktop**: 28.3.2
- **Docker Compose**: v2.39.1
- **Prometheus**: v2.52.0
- **Alertmanager**: v0.26.0
- **Grafana**: 10.4.1
- **Mailpit**: v1.15 (для тестирования Email)
- **Python**: 3.11
- **FastAPI**: 0.110.0
- **prometheus-client**: 0.20.0

---

## АРХИТЕКТУРА СИСТЕМЫ МОНИТОРИНГА

Система состоит из следующих компонентов:

1. **Приложение** (`demo-monitoring-app`) - FastAPI сервис, экспортирующий метрики в формате Prometheus
2. **Prometheus** - сбор и хранение метрик, оценка правил алертинга
3. **Alertmanager** - маршрутизация и отправка уведомлений
4. **Grafana** - визуализация метрик и дашборды
5. **Telegram Webhook** - сервис-прокси для отправки уведомлений в Telegram
6. **Mailpit** - тестовый SMTP сервер для проверки Email-уведомлений

Все компоненты развернуты в Docker и объединены в единую сеть `monitoring_net`.

---

## РАЗВЕРТЫВАНИЕ ПРИЛОЖЕНИЯ С МЕТРИКАМИ PROMETHEUS

### Структура проекта

```
5 практ/
├── app/
│   ├── main.py          # FastAPI приложение с метриками
│   ├── requirements.txt # Зависимости Python
│   └── Dockerfile       # Образ приложения
├── prometheus/
│   ├── prometheus.yml   # Конфигурация Prometheus
│   └── rules/
│       └── alert_rules.yml  # Правила алертинга
├── alertmanager/
│   ├── alertmanager.yml # Конфигурация Alertmanager
│   └── .env             # Переменные окружения
├── telegram-webhook/
│   ├── webhook.py       # Сервис для отправки в Telegram
│   └── Dockerfile
├── grafana/
│   ├── provisioning/
│   │   ├── datasources/ # Автоматическая настройка Prometheus
│   │   └── dashboards/   # Автоматическая загрузка дашбордов
│   └── dashboards/
│       └── practice5_dashboard.json
└── docker-compose.yml   # Оркестрация всех сервисов
```

### Приложение с метриками

Приложение на FastAPI (`app/main.py`) экспортирует метрики через endpoint `/metrics`:

**Стандартные метрики** (автоматически собираются `prometheus-client`):
- `process_cpu_seconds_total` - использование CPU
- `process_resident_memory_bytes` - использование памяти
- `python_gc_objects_collected_total` - сборка мусора Python

**Пользовательские метрики**:
- `app_active_users` (Gauge) - количество активных пользователей
- `app_database_size_megabytes` (Gauge) - размер базы данных
- `app_cache_hit_ratio` (Gauge) - коэффициент попаданий в кеш
- `app_orders_processed_total` (Counter) - количество обработанных заказов
- `app_business_errors_total` (Counter) - количество бизнес-ошибок
- `app_http_requests_total` (Counter) - количество HTTP-запросов
- `app_http_request_duration_seconds` (Histogram) - задержка HTTP-запросов
- `app_inflight_requests` (Gauge) - запросы в обработке

**Важно**: Метрики сохраняют состояние между перезапусками приложения, так как значения хранятся в памяти процесса и не сбрасываются при рестарте контейнера (при условии, что контейнер не пересоздается).

### Запуск системы

```bash
cd "5 практ"
docker compose up -d
```

**Проверка работы приложения**:
```bash
curl http://localhost:8000/metrics | grep app_active_users
# app_active_users 103.0
```

---

## СТАНДАРТНЫЕ МЕТРИКИ ПРОИЗВОДИТЕЛЬНОСТИ

Для анализа производительности выбраны три стандартные метрики:

### 1. Использование CPU (`process_cpu_seconds_total`)

**Тип**: Counter  
**Описание**: Общее время использования CPU процессом  
**Визуализация**: График временных рядов с легендой "CPU ({{instance}})"  
**Формула в Grafana**: `rate(process_cpu_seconds_total{job='demo_app'}[1m])`  
**Единица измерения**: Проценты (percentunit)

**Назначение**: Позволяет отслеживать нагрузку на процессор и выявлять узкие места производительности.

### 2. Использование памяти (`process_resident_memory_bytes`)

**Тип**: Gauge  
**Описание**: Размер резидентной памяти процесса  
**Визуализация**: График временных рядов с легендой "RSS {{instance}}"  
**Формула в Grafana**: `process_resident_memory_bytes{job='demo_app'}`  
**Единица измерения**: Байты (bytes)

**Назначение**: Контроль потребления памяти для предотвращения утечек и оптимизации ресурсов.

### 3. Сборка мусора Python (`python_gc_objects_collected_total`)

**Тип**: Counter  
**Описание**: Количество объектов, собранных сборщиком мусора  
**Визуализация**: График временных рядов с легендой "GC {{generation}}"  
**Формула в Grafana**: `rate(python_gc_objects_collected_total{job='demo_app'}[5m])`  
**Единица измерения**: Объекты в секунду

**Назначение**: Мониторинг активности сборщика мусора для оценки эффективности управления памятью.

---

## ПОЛЬЗОВАТЕЛЬСКИЕ МЕТРИКИ ПРИЛОЖЕНИЯ

Разработаны три уникальные метрики, отражающие специфику проекта:

### 1. Активные пользователи (`app_active_users`)

**Тип**: Gauge  
**Описание**: Текущее количество активных пользователей в системе  
**Визуализация**: График временных рядов с легендой "Active users"  
**Формула в Grafana**: `app_active_users`  
**Единица измерения**: Количество (none)

**Бизнес-логика**: Метрика обновляется при создании заказов и симулируется фоновой задачей. Используется для мониторинга нагрузки на систему и планирования масштабирования.

**Пример использования**:
```bash
curl "http://localhost:8000/simulate/load?multiplier=80"
# Увеличивает активных пользователей на 400
```

### 2. Размер базы данных (`app_database_size_megabytes`)

**Тип**: Gauge  
**Описание**: Размер базы данных в мегабайтах  
**Визуализация**: График временных рядов с легендой "DB size"  
**Формула в Grafana**: `app_database_size_megabytes`  
**Единица измерения**: Мегабайты (decbytes)

**Бизнес-логика**: Симулируется постепенным ростом с небольшими флуктуациями. Критична для планирования резервного копирования и мониторинга роста данных.

### 3. Коэффициент попаданий в кеш (`app_cache_hit_ratio`)

**Тип**: Gauge  
**Описание**: Доля успешных попаданий в кеш (от 0 до 1)  
**Визуализация**: График временных рядов с легендой "Cache hit ratio"  
**Формула в Grafana**: `app_cache_hit_ratio`  
**Единица измерения**: Проценты (percentunit, max=1)

**Бизнес-логика**: Показывает эффективность кеширования. Низкие значения указывают на необходимость оптимизации стратегии кеширования.

---

## НАСТРОЙКА ВИЗУАЛИЗАЦИИ В GRAFANA

### Автоматический провижининг

Grafana автоматически настраивается при запуске через провижининг:

**Источник данных** (`grafana/provisioning/datasources/datasource.yml`):
```yaml
datasources:
  - name: Prometheus
    type: prometheus
    url: http://prometheus:9090
    isDefault: true
```

**Дашборд** (`grafana/dashboards/practice5_dashboard.json`):
- Автоматически загружается при старте Grafana
- Содержит 8 панелей с метриками
- Обновление каждые 10 секунд
- Временной диапазон: последние 30 минут

### Панели дашборда

1. **CPU (process_cpu_seconds_total)** - Timeseries, легенда "CPU ({{instance}})"
2. **Память процесса** - Timeseries, легенда "RSS {{instance}}"
3. **Сборка мусора Python** - Timeseries, легенда "GC {{generation}}"
4. **Активные пользователи** - Timeseries, легенда "Active users"
5. **Размер БД** - Timeseries, легенда "DB size"
6. **Коэффициент попаданий кеша** - Timeseries, легенда "Cache hit ratio"
7. **95-й перцентиль задержки** - Timeseries, легенда "p95 latency"
8. **Ошибки бизнеса (5м)** - Timeseries, легенда "{{error_type}}"

**Легенды настроены** для каждой панели, отображают ключевые данные (метки, значения, агрегации).

**Доступ к Grafana**: http://localhost:3000 (admin/admin123)

---

## НАСТРОЙКА АЛЕРТИНГА

### Правила алертинга в Prometheus

Файл `prometheus/rules/alert_rules.yml` содержит три правила:

#### 1. HighRequestLatency

```yaml
- alert: HighRequestLatency
  expr: histogram_quantile(0.95, rate(app_http_request_duration_seconds_bucket[2m])) > 1
  for: 30s
  labels:
    severity: critical
    channel: performance
  annotations:
    summary: "Высокая задержка ответа приложения"
    description: "95-й перцентиль времени ответа превышает 1 секунду."
```

**Условие**: 95-й перцентиль задержки > 1 секунда в течение 30 секунд  
**Severity**: critical

#### 2. ActiveUsersSurge

```yaml
- alert: ActiveUsersSurge
  expr: app_active_users > 250
  for: 45s
  labels:
    severity: warning
    channel: product
  annotations:
    summary: "Резкий рост активных пользователей"
    description: "Количество активных пользователей перевалило за 250."
```

**Условие**: Активных пользователей > 250 в течение 45 секунд  
**Severity**: warning

#### 3. BusinessErrorsSpike

```yaml
- alert: BusinessErrorsSpike
  expr: increase(app_business_errors_total[5m]) > 5
  for: 30s
  labels:
    severity: critical
    channel: incidents
  annotations:
    summary: "Рост бизнес-ошибок"
    description: "За последние 5 минут зафиксировано более 5 бизнес-ошибок."
```

**Условие**: Рост ошибок > 5 за 5 минут в течение 30 секунд  
**Severity**: critical

---

## ИНТЕГРАЦИЯ С TELEGRAM И EMAIL

### Архитектура уведомлений

Alertmanager получает алерты от Prometheus и маршрутизирует их в два канала:
1. **Telegram** - через webhook-сервис
2. **Email** - через SMTP (Mailpit для тестирования)

### Telegram Webhook

Создан отдельный сервис `telegram-webhook` (`telegram-webhook/webhook.py`), который:
- Принимает POST-запросы от Alertmanager
- Форматирует сообщения в Markdown
- Отправляет в Telegram через Bot API

**Конфигурация Alertmanager**:
```yaml
receivers:
  - name: 'telegram'
    webhook_configs:
      - url: 'http://telegram-webhook:5000/webhook'
        send_resolved: true
```

**Формат сообщения**:
```
*FIRING*: HighRequestLatency
*Severity*: critical
*Summary*: Высокая задержка ответа приложения
*Description*: 95-й перцентиль времени ответа превышает 1 секунду.
```

### Email уведомления

**Конфигурация Alertmanager**:
```yaml
receivers:
  - name: 'email'
    email_configs:
      - to: 'operations@demo-monitoring.local'
        send_resolved: true
        headers:
          subject: '[Monitoring] {{ .Status | toUpper }}: {{ .CommonLabels.alertname }}'
```

**Проверка Email**: http://localhost:8025 (Mailpit UI)

### Статусы алертов

Alertmanager поддерживает следующие статусы:
- **Firing** - алерт активен, условие выполнено
- **Pending** - условие выполнено, но еще не прошло время `for`
- **Resolved** - условие больше не выполняется, алерт разрешен

Все статусы отправляются в Telegram и Email благодаря параметру `send_resolved: true`.

---

## ДЕМОНСТРАЦИЯ РАБОТЫ АЛЕРТОВ

### Вызов алерта HighRequestLatency

```bash
# Увеличиваем нагрузку, что приводит к росту задержки
curl "http://localhost:8000/simulate/load?multiplier=80"
```

**Результат**:
- Prometheus обнаруживает превышение порога задержки
- Через 30 секунд алерт переходит в состояние **Firing**
- Alertmanager отправляет уведомление в Telegram и Email
- В Telegram приходит сообщение с форматированием Markdown

![Уведомление в Telegram о срабатывании алерта HighRequestLatency](Снимок%20экрана%202025-11-13%20в%202.52.17%20PM.png)

*Рисунок 1: Уведомление в Telegram о срабатывании алерта HighRequestLatency со статусом FIRING*

**Логи telegram-webhook**:
```
Telegram response: 200 - {"ok":true,"result":{"message_id":67,...}}
```

### Вызов алерта ActiveUsersSurge

```bash
# Увеличиваем активных пользователей выше порога 250
curl "http://localhost:8000/simulate/load?multiplier=80"
```

**Результат**:
- Метрика `app_active_users` превышает 250
- Через 45 секунд алерт срабатывает
- Уведомления отправляются в оба канала

### Разрешение алерта (Resolved)

```bash
# Сбрасываем метрики
curl -X POST http://localhost:8000/simulate/reset
```

**Результат**:
- Метрики возвращаются к нормальным значениям
- Prometheus обнаруживает, что условие больше не выполняется
- Alertmanager отправляет уведомление **Resolved** в Telegram и Email

### Проверка состояния алертов

**Prometheus API**:
```bash
curl http://localhost:9090/api/v1/alerts | jq '.data.alerts[]? | {name: .labels.alertname, state: .state}'
```

**Alertmanager API**:
```bash
curl http://localhost:9093/api/v2/alerts | jq '.'
```

---

## ДОПОЛНИТЕЛЬНЫЕ МАТЕРИАЛЫ И СКРИНШОТЫ

Рекомендуемые скриншоты для отчета:

1. **Docker Compose** - список запущенных контейнеров
2. **Prometheus UI** (http://localhost:9090) - страница Targets, показывающая успешный scrape приложения
3. **Prometheus Alerts** - страница Alerts с активными алертами
4. **Grafana Dashboard** - общий вид дашборда "Практика 5: Мониторинг приложения"
5. **Grafana Panel** - детальный вид одной из панелей с легендой
6. **Telegram** - скриншот полученного уведомления в Telegram (см. Рисунок 1 в разделе "Демонстрация работы алертов")
7. **Mailpit UI** (http://localhost:8025) - список полученных Email-уведомлений
8. **Alertmanager UI** (http://localhost:9093) - страница с активными алертами

---

## ВЫВОДЫ

В ходе практической работы:

1. ✅ **Развернута система мониторинга** на базе Prometheus и Grafana в Docker
2. ✅ **Реализован сбор метрик** в формате Prometheus из FastAPI приложения
3. ✅ **Выбраны и визуализированы три стандартные метрики** производительности (CPU, память, GC) с настроенными легендами
4. ✅ **Разработаны три пользовательские метрики** (активные пользователи, размер БД, коэффициент кеша), отражающие специфику проекта
5. ✅ **Настроена визуализация в Grafana** с автоматическим провиженингом дашборда и источников данных
6. ✅ **Реализован алертинг** через Prometheus Alertmanager с тремя правилами
7. ✅ **Настроена интеграция с Telegram** через webhook-сервис с успешной доставкой сообщений
8. ✅ **Настроена интеграция с Email** через SMTP (Mailpit) с подтверждением доставки
9. ✅ **Продемонстрированы все статусы алертов**: Firing, Pending, Resolved

**Особенности реализации**:
- Метрики сохраняют состояние между перезапусками (не сбрасываются)
- Все компоненты работают в единой Docker-сети
- Автоматическая настройка Grafana через провижининг
- Двухканальная система уведомлений (Telegram + Email)

Система готова к использованию в production-окружении после настройки реальных SMTP-серверов и токенов Telegram.

---

